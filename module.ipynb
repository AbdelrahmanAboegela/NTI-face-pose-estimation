{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_height = 128\n",
    "desired_width = 128\n",
    "TRIANGLE_SIZE = 100\n",
    "VIDEO_OUTPUT_FILE = 'output_with_triangle.avi'\n",
    "def load_data(image_folder, mat_folder):\n",
    "    print(\"Loading data...\")\n",
    "    images, poses = [], []\n",
    "    image_files = sorted([f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))])\n",
    "    mat_files = sorted([f for f in os.listdir(mat_folder) if f.endswith('.mat')])\n",
    "\n",
    "    for image_file, mat_file in zip(image_files, mat_files):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        mat_path = os.path.join(mat_folder, mat_file)\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Could not load image {image_file}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        mat_data = loadmat(mat_path)\n",
    "        \n",
    "        if 'Pose_Para' not in mat_data:\n",
    "            print(f\"'Pose_Para' key not found in {mat_file}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        ground_truth_poses = mat_data['Pose_Para']  \n",
    "        poses.append(ground_truth_poses.flatten()) \n",
    "        \n",
    "        images.append(image)\n",
    "\n",
    "    print(f\"Loaded {len(images)} images and {len(poses)} pose data.\")\n",
    "    return images, np.array(poses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(images, poses, test_size=0.2):\n",
    "    return train_test_split(images, poses, test_size=test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pose(image, landmarks):\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),           \n",
    "        (0.0, -330.0, -65.0),      \n",
    "        (-225.0, 170.0, -135.0),   \n",
    "        (225.0, 170.0, -135.0),    \n",
    "        (-150.0, -150.0, -125.0),  \n",
    "        (150.0, -150.0, -125.0)    \n",
    "    ])\n",
    "    \n",
    "    image_points = np.array([\n",
    "        (landmarks[1].x * image.shape[1], landmarks[1].y * image.shape[0]),     \n",
    "        (landmarks[152].x * image.shape[1], landmarks[152].y * image.shape[0]), \n",
    "        (landmarks[33].x * image.shape[1], landmarks[33].y * image.shape[0]),   \n",
    "        (landmarks[263].x * image.shape[1], landmarks[263].y * image.shape[0]), \n",
    "        (landmarks[61].x * image.shape[1], landmarks[61].y * image.shape[0]),   \n",
    "        (landmarks[291].x * image.shape[1], landmarks[291].y * image.shape[0])  \n",
    "    ], dtype=\"double\")\n",
    "\n",
    "    focal_length = image.shape[1]  \n",
    "    center = (image.shape[1] / 2, image.shape[0] / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1)) \n",
    "\n",
    "    success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "        model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "\n",
    "    if not success:\n",
    "        raise ValueError(\"Pose estimation failed\")\n",
    "\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "\n",
    "    sy = np.sqrt(rotation_matrix[0, 0] * rotation_matrix[0, 0] + rotation_matrix[1, 0] * rotation_matrix[1, 0])\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x_angle = np.arctan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n",
    "        y_angle = np.arctan2(-rotation_matrix[2, 0], sy)\n",
    "        z_angle = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "    else:\n",
    "        x_angle = np.arctan2(-rotation_matrix[1, 2], rotation_matrix[1, 1])\n",
    "        y_angle = np.arctan2(-rotation_matrix[2, 0], sy)\n",
    "        z_angle = 0\n",
    "\n",
    "    pitch = np.degrees(x_angle)\n",
    "    yaw = np.degrees(y_angle)\n",
    "    roll = np.degrees(z_angle)\n",
    "\n",
    "    return pitch, yaw, roll\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    try:\n",
    "        image_resized = cv2.resize(image, (desired_width, desired_height))\n",
    "        return image_resized\n",
    "    except cv2.error as e:\n",
    "        print(\"Error resizing image:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, ground_truths):\n",
    "    predictions = np.array(predictions)\n",
    "    ground_truths = np.array(ground_truths)\n",
    "    \n",
    "    mae = np.mean(np.abs(predictions - ground_truths), axis=0)\n",
    "    rmse = np.sqrt(np.mean((predictions - ground_truths) ** 2, axis=0))\n",
    "    \n",
    "    return mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pose_lines(frame, pitch, yaw, roll):\n",
    "    # Define the center of the image\n",
    "    height, width = frame.shape[:2]\n",
    "    center_x, center_y = width // 2, height // 2\n",
    "    \n",
    "    # Define line length\n",
    "    line_length = 1000\n",
    "\n",
    "    # Calculate end points of the lines based on pitch, yaw, and roll\n",
    "    pitch_end = (center_x, center_y - int(line_length * np.sin(np.radians(pitch))))\n",
    "    yaw_end = (center_x + int(line_length * np.sin(np.radians(yaw))), center_y)\n",
    "    roll_end = (center_x, center_y + int(line_length * np.sin(np.radians(roll))))\n",
    "    \n",
    "    # Draw lines on the frame\n",
    "    cv2.line(frame, (center_x, center_y), pitch_end, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.line(frame, (center_x, center_y), yaw_end, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.line(frame, (center_x, center_y), roll_end, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Add text for pitch, yaw, and roll\n",
    "    cv2.putText(frame, f\"Pitch: {pitch:.2f}\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Yaw: {yaw:.2f}\", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    cv2.putText(frame, f\"Roll: {roll:.2f}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(images, poses):\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "    all_predictions = []\n",
    "    all_ground_truths = []\n",
    "\n",
    "    for idx, (image, ground_truth) in enumerate(zip(images, poses)):\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        with mp_face_mesh.FaceMesh(static_image_mode=True) as face_mesh:\n",
    "            results = face_mesh.process(image_rgb)\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                face_landmarks = results.multi_face_landmarks[0]\n",
    "                landmarks = face_landmarks.landmark\n",
    "\n",
    "                try:\n",
    "                    pitch, yaw, roll = estimate_pose(image, landmarks)\n",
    "                    pose_estimation = np.array([pitch, yaw, roll])\n",
    "                    \n",
    "                    if ground_truth.shape[0] >= 3:\n",
    "                        all_predictions.append(pose_estimation)\n",
    "                        all_ground_truths.append(ground_truth[:3])\n",
    "\n",
    "                    print(f\"Processing image {idx}...\")\n",
    "                    print(f\"Ground truth shape: {ground_truth.shape}\")\n",
    "                    print(f\"Pose estimation shape: {pose_estimation.shape}\")\n",
    "                    print(f\"Pose estimation: Pitch: {pitch}, Yaw: {yaw}, Roll: {roll}\")\n",
    "\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error processing image {idx}: {e}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"No face detected in image {idx}.\")\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_ground_truths = np.array(all_ground_truths)\n",
    "\n",
    "    mae, rmse = calculate_metrics(all_predictions, all_ground_truths)\n",
    "    if mae is not None and rmse is not None:\n",
    "        print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_camera():\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    camera_indices = [0, 1]  # Try different camera indices\n",
    "    cap = None\n",
    "\n",
    "    # Try different camera indices to find an accessible one\n",
    "    for index in camera_indices:\n",
    "        cap = cv2.VideoCapture(index)\n",
    "        if cap.isOpened():\n",
    "            print(f\"Camera index {index} is accessible.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Camera index {index} is not accessible.\")\n",
    "\n",
    "    if not cap or not cap.isOpened():\n",
    "        print(\"Error: Camera not accessible.\")\n",
    "        return\n",
    "\n",
    "    out = cv2.VideoWriter(VIDEO_OUTPUT_FILE, cv2.VideoWriter_fourcc(*'XVID'), 30, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Cannot read frame from camera.\")\n",
    "                break\n",
    "\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(image_rgb)\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                face_landmarks = results.multi_face_landmarks[0]\n",
    "                landmarks = face_landmarks.landmark\n",
    "\n",
    "                try:\n",
    "                    pitch, yaw, roll = estimate_pose(frame, landmarks)\n",
    "                    draw_pose_lines(frame, pitch, yaw, roll)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error processing frame: {e}\")\n",
    "\n",
    "            out.write(frame)\n",
    "            cv2.imshow('Camera', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_folder = '/home/ahmed/Documents/GitHub/NTI-face-pose-statment-1/DataSet'\n",
    "    mat_folder = '/home/ahmed/Documents/GitHub/NTI-face-pose-statment-1/DataSet'\n",
    "    images, poses = load_data(image_folder, mat_folder)\n",
    "    train_images, test_images, train_poses, test_poses = split_data(images, poses)\n",
    "\n",
    "    print(\"Processing training data...\")\n",
    "    process_data(train_images, train_poses)\n",
    "\n",
    "    print(\"Processing testing data...\")\n",
    "    process_data(test_images, test_poses)\n",
    "\n",
    "    print(\"Testing with camera...\")\n",
    "    test_with_camera()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
